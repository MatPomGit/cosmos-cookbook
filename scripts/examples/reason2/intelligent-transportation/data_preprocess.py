# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
ğŸ“ SKRYPT PRZETWARZANIA DANYCH WTS (WovenTraffic Safety)

CO ROBI TEN SKRYPT:
Ten skrypt przeksztaÅ‚ca surowe adnotacje (annotacje) z zestawu danych WTS
do formatu uÅ¼ywanego przez modele AI do uczenia siÄ™ rozumienia scen drogowych.

WTS (WovenTraffic Safety) to zbiÃ³r danych z wideo ruchu drogowego zawierajÄ…cy:
- Nagrania z gÃ³ry (overhead view) pokazujÄ…ce skrzyÅ¼owania
- Pytania wielokrotnego wyboru (MCQ) o bezpieczeÅ„stwo i sytuacje na drodze
- Adnotacje Å›rodowiska (environment) - warunki pogodowe, pora dnia, etc.

DLACZEGO PRZETWARZAMY DANE:
Surowe dane sÄ… w jednym formacie, ale model AI wymaga innego formatu (LLaVA).
To jak tÅ‚umaczenie miÄ™dzy jÄ™zykami - te same informacje, inna struktura.

FORMAT LLaVA:
LLaVA to format konwersacji, gdzie:
- "human" zadaje pytanie (z referencjÄ… do wideo)
- "gpt" odpowiada (prawidÅ‚owa odpowiedÅº)

PRZYKÅAD TRANSFORMACJI:
PRZED (surowe dane):
{
    "question": "Jaka jest pogoda?",
    "a": "sÅ‚onecznie",
    "b": "deszczowo",
    "correct": "a"
}

PO (format LLaVA):
{
    "video": "path/to/video.mp4",
    "conversations": [
        {"from": "human", "value": "<video> Jaka jest pogoda? A: sÅ‚onecznie B: deszczowo"},
        {"from": "gpt", "value": "A"}
    ]
}
"""

# ğŸ“ IMPORTY - biblioteki potrzebne do pracy ze skryptem
import argparse  # Do parsowania argumentÃ³w z linii poleceÅ„
import json      # Do czytania i zapisywania plikÃ³w JSON (format przechowywania danych)
import os        # Do operacji na plikach i katalogach
from pathlib import Path  # Do wygodnej pracy ze Å›cieÅ¼kami
from typing import Any, Dict, List, Optional, Tuple  # Typy dla lepszej czytelnoÅ›ci kodu

from tqdm import tqdm  # Pasek postÄ™pu - pokazuje ile pracy jeszcze zostaÅ‚o


def parse_arguments() -> str:
    """Parsuj argumenty z linii poleceÅ„.

    ğŸ“ WYJAÅšNIENIE - CO TO SÄ„ ARGUMENTY LINII POLECEÅƒ:
    Gdy uruchamiasz program z terminala, moÅ¼esz przekazaÄ‡ mu informacje:
    python script.py --data_path /Å›cieÅ¼ka/do/danych
    
    --data_path to "argument" - informacja ktÃ³rÄ… przekazujesz programowi.
    
    DLACZEGO TO JEST UÅ»YTECZNE:
    - Nie musisz zmieniaÄ‡ kodu by uÅ¼yÄ‡ innej Å›cieÅ¼ki
    - Ten sam skrypt dziaÅ‚a z rÃ³Å¼nymi danymi
    - Åatwiejsza automatyzacja
    
    Returns:
        str: ÅšcieÅ¼ka do katalogu zawierajÄ…cego pliki JSON z adnotacjami
        
    PRZYKÅAD UÅ»YCIA:
    python data_preprocess.py --data_path /home/user/wts_data
    """
    parser = argparse.ArgumentParser(
        description="Formatuj adnotacje WTS do generowania danych treningowych (best view)"
    )
    parser.add_argument(
        "--data_path", 
        type=Path, 
        required=True, 
        help="Katalog z plikami JSON adnotacji"
    )
    args = parser.parse_args()
    return str(args.data_path)


def process_question(row: Dict[str, Any]) -> str:
    """PrzetwÃ³rz pytanie do formatu promptu z opcjami wielokrotnego wyboru.

    ğŸ“ WYJAÅšNIENIE - CO TO JEST MCQ (Multiple Choice Question):
    MCQ to pytanie z kilkoma opcjami odpowiedzi, gdzie tylko jedna jest prawidÅ‚owa.
    PrzykÅ‚ad:
    "Jaki kolor ma niebo?
     A: Zielony
     B: Niebieski
     C: Czerwony"
    
    DLACZEGO TAK FORMATUJEMY:
    Model AI musi "widzieÄ‡" pytanie w okreÅ›lonym formacie:
    1. <video> - znacznik mÃ³wiÄ…cy "tu jest wideo"
    2. Pytanie
    3. Opcje A, B, C, D
    
    To jak wypeÅ‚nianie formularza egzaminacyjnego - musi byÄ‡ w standardowej formie.

    Args:
        row: SÅ‚ownik z danymi pytania zawierajÄ…cy:
            - 'question': Tekst pytania
            - 'a', 'b', 'c', 'd': Opcje odpowiedzi (opcjonalne)

    Returns:
        Sformatowany prompt w formacie: "<video> \n [pytanie] \n A: ... B: ..."
        
    PRZYKÅAD:
    Input: {"question": "Jaka pogoda?", "a": "sÅ‚onecznie", "b": "deszczowo"}
    Output: "<video> \n Jaka pogoda? \n A: sÅ‚onecznie \n B: deszczowo \n "
    """
    # ğŸ“ Rozpocznij od znacznika <video> i pytania
    prompt = f"<video> \n {row['question']} \n "

    # ğŸ“ Dodaj wszystkie dostÄ™pne opcje odpowiedzi (A, B, C, D)
    # Iterujemy przez wszystkie moÅ¼liwe opcje
    for option in ["a", "b", "c", "d"]:
        # SprawdÅº czy ta opcja istnieje w danych
        if option in row:
            # Dodaj opcjÄ™ w formacie "A: odpowiedÅº"
            # option.upper() zmienia 'a' na 'A'
            prompt += f"{option.upper()}: {row[option]} \n "

    return prompt


def format_training_data_mcq_llava(
    id: str,
    video_file: str,
    question: str,
    answer: str,
    qtype: str,
    phase: str,
    wts_id: str,
) -> Dict[str, Any]:
    """Formatuj dane treningowe dla zadaÅ„ MCQ w formacie konwersacji LLaVA.

    ğŸ“ WYJAÅšNIENIE - FORMAT LLaVA:
    LLaVA to format uÅ¼ywany przez modele vision-language (widzenie + jÄ™zyk).
    Przedstawia dane jako "konwersacjÄ™" miÄ™dzy czÅ‚owiekiem a AI.
    
    STRUKTURA KONWERSACJI:
    1. "human" (czÅ‚owiek) - zadaje pytanie, pokazuje wideo
    2. "gpt" (model AI) - odpowiada
    
    DLACZEGO TAK:
    - Modele AI uczÄ… siÄ™ przez "rozmowÄ™"
    - To naturalna forma interakcji
    - Åatwa do walidacji (jedna odpowiedÅº = jeden przykÅ‚ad)

    Args:
        id: Unikalny identyfikator prÃ³bki treningowej (np. "video1_q3")
        video_file: ÅšcieÅ¼ka do pliku wideo (np. "scene123/overhead_view/cam1.mp4")
        question: Tekst pytania z opcjami MCQ (juÅ¼ sformatowany przez process_question)
        answer: PrawidÅ‚owa odpowiedÅº (litera A, B, C lub D)
        qtype: Typ pytania (np. "environment", "behavior", "safety")
        phase: Faza sceny drogowej (np. "full_video", "before_incident")
        wts_id: Identyfikator sceny WTS (np. "WTS_001234")

    Returns:
        SÅ‚ownik z danymi treningowymi w formacie LLaVA:
        {
            "id": ...,           # Identyfikator
            "video": ...,        # ÅšcieÅ¼ka do wideo
            "type": ...,         # Typ pytania
            "conversations": [   # Konwersacja human-gpt
                {"from": "human", "value": "pytanie..."},
                {"from": "gpt", "value": "A"}
            ]
        }
        
    ğŸ“ PRZYKÅAD TRANSFORMACJI:
    Input:
        id="scene1_0"
        video_file="scene1/overhead_view/video.mp4"
        question="<video> Jaka pogoda? A: sÅ‚onecznie B: deszczowo"
        answer="a"
        
    Output:
        {
            "id": "scene1_0",
            "video": "scene1/overhead_view/video.mp4",
            "conversations": [
                {
                    "from": "human",
                    "value": "<video> Jaka pogoda? A: sÅ‚onecznie B: deszczowo\nAnswer with..."
                },
                {"from": "gpt", "value": "A"}
            ]
        }
    """
    # ğŸ“ UtwÃ³rz sÅ‚ownik z wszystkimi metadanymi
    item = {
        "id": id,              # Unikalny identyfikator prÃ³bki
        "wts_id": wts_id,      # ID sceny w zbiorze WTS
        "video": video_file,   # ÅšcieÅ¼ka do wideo
        "type": qtype,         # Typ pytania (do pÃ³Åºniejszej analizy)
        "phase": phase,        # Faza sceny (do pÃ³Åºniejszej analizy)
        
        # ğŸ“ Kluczowa czÄ™Å›Ä‡ - konwersacja w formacie LLaVA
        "conversations": [
            {
                "from": "human",  # Pytanie od czÅ‚owieka
                "value": question
                + "\nAnswer with the option's letter from the given choices directly.",
                # ğŸ“ Instrukcja: "Odpowiedz literÄ… opcji bezpoÅ›rednio"
                # To mÃ³wi modelowi jak ma sformatowaÄ‡ odpowiedÅº
            },
            {
                "from": "gpt",           # OdpowiedÅº od modelu
                "value": answer.upper()  # Litera w wersji wielkiej (A, B, C, D)
            },
        ],
    }
    return item


def process_wts_environment_mcq(root_dir: str, split: str) -> List[Dict]:
    """PrzetwÃ³rz dane MCQ dotyczÄ…ce Å›rodowiska z widokÃ³w WTS.

    ğŸ“ WYJAÅšNIENIE - CO TO SÄ„ PYTANIA O ÅšRODOWISKO:
    "Environment" (Å›rodowisko) to pytania o warunki w ktÃ³rych odbywa siÄ™ scena:
    - Pogoda (sÅ‚onecznie, deszczowo, mgliÅ›cie)
    - Pora dnia (dzieÅ„, noc, zmierzch)
    - Stan drogi (sucha, mokra, oblodzona)
    - WidocznoÅ›Ä‡ (dobra, ograniczona)
    
    DLACZEGO TO JEST WAÅ»NE:
    Warunki Å›rodowiskowe wpÅ‚ywajÄ… na bezpieczeÅ„stwo ruchu drogowego.
    Model musi nauczyÄ‡ siÄ™ rozpoznawaÄ‡ te warunki z wideo.

    STRUKTURA DANYCH WTS:
    WTS/
    â”œâ”€â”€ scene_001/
    â”‚   â”œâ”€â”€ overhead_view/        # Wideo z gÃ³ry
    â”‚   â”‚   â”œâ”€â”€ video1.mp4
    â”‚   â”‚   â””â”€â”€ video2.mp4
    â”‚   â””â”€â”€ environment/          # Adnotacje Å›rodowiska
    â”‚       â””â”€â”€ scene_001.json
    â”œâ”€â”€ scene_002/
    â””â”€â”€ ...

    Args:
        root_dir: Bazowa Å›cieÅ¼ka do plikÃ³w wejÅ›ciowych (katalog ze scenami)
        split: Nazwa podziaÅ‚u danych ("train", "val", "test")

    Returns:
        Lista sÅ‚ownikÃ³w z sformatowanymi danymi MCQ dla wszystkich scen
        
    ğŸ“ PROCES KROK PO KROKU:
    1. PrzejdÅº przez wszystkie katalogi scen
    2. Dla kaÅ¼dej sceny, zaÅ‚aduj plik environment JSON
    3. Dla kaÅ¼dego wideo w scenie:
       - Dla kaÅ¼dego pytania o Å›rodowisko:
         - PrzetwÃ³rz pytanie (dodaj opcje A, B, C, D)
         - Sformatuj do LLaVA
         - Dodaj do listy wynikowej
    4. ZwrÃ³Ä‡ wszystkie przetworzone prÃ³bki
    """
    # ğŸ“ Lista do przechowywania wszystkich przetworzonych prÃ³bek
    mcq_env_dataset = []
    root_dir = os.path.join(root_dir)

    # ğŸ“ PrzejdÅº przez wszystkie katalogi w root_dir
    # tqdm() pokazuje pasek postÄ™pu - widzisz ile pracy zostaÅ‚o
    for name in tqdm(os.listdir(root_dir)):
        # ğŸ“ PomiÅ„ pliki "normal_trimmed" - sÄ… przetwarzane osobno
        if "normal_trimmed" in name:
            continue

        # ğŸ“ Skonstruuj Å›cieÅ¼kÄ™ do pliku JSON z adnotacjami Å›rodowiska
        # Struktura: root_dir/nazwa_sceny/environment/nazwa_sceny.json
        env_file = os.path.join(root_dir, name, "environment", name + ".json")
        
        # ğŸ“ SprawdÅº czy plik istnieje (moÅ¼e byÄ‡ niepeÅ‚ny zbiÃ³r danych)
        if not os.path.exists(env_file):
            print(f"Environment file not found for {name}")
            continue

        # ğŸ“ ZaÅ‚aduj plik JSON z adnotacjami
        with open(env_file, "r") as e:
            data = json.load(e)

        # ğŸ“ Pobierz ID sceny WTS (uÅ¼ywane do Å›ledzenia)
        wts_id = data[0]["id"]

        # ğŸ“ PrzetwÃ³rz pytania o Å›rodowisko dla kaÅ¼dego wideo w scenie
        for vid in data[0]["overhead_videos"]:
            # ğŸ“ UsuÅ„ rozszerzenie pliku (.mp4) do tworzenia ID
            fir = vid[:-4]
            cnt = 0  # Licznik pytaÅ„ dla tego wideo
            
            # ğŸ“ Skonstruuj peÅ‚nÄ… Å›cieÅ¼kÄ™ do pliku wideo
            vid2 = os.path.join(name, "overhead_view", vid)
            
            # ğŸ“ Specjalna obsÅ‚uga dla "normal_trimmed" - dodaj prefix
            if "normal_trimmed" in root_dir:
                vid2 = "normal_trimmed/" + vid2

            # ğŸ“ PrzetwÃ³rz kaÅ¼de pytanie o Å›rodowisko
            for row in data[0]["environment"]:
                # ğŸ“ UtwÃ³rz unikalny identyfikator: nazwa_pliku_numer_pytania
                lab = fir + "_" + str(cnt)
                
                # ğŸ“ KROK 1: PrzetwÃ³rz pytanie (dodaj opcje A, B, C, D)
                question = process_question(row)
                
                # ğŸ“ KROK 2: Sformatuj do formatu LLaVA
                item = format_training_data_mcq_llava(
                    lab,                 # ID prÃ³bki
                    vid2,                # ÅšcieÅ¼ka do wideo
                    question,            # Sformatowane pytanie
                    row["correct"],      # PrawidÅ‚owa odpowiedÅº (a, b, c, d)
                    "environment",       # Typ pytania
                    "full_video",        # Faza (peÅ‚ne wideo)
                    wts_id,             # ID sceny WTS
                )
                
                # ğŸ“ KROK 3: Dodaj do zbioru danych
                mcq_env_dataset.append(item)
                cnt += 1  # ZwiÄ™ksz licznik pytaÅ„

    return mcq_env_dataset


def main():
    """GÅ‚Ã³wna funkcja wykonawcza orkiestrujÄ…ca kompletny pipeline przetwarzania danych.

    ğŸ“ WYJAÅšNIENIE - CO TO JEST PIPELINE:
    Pipeline to "rurociÄ…g" - sekwencja krokÃ³w przetwarzania danych.
    KaÅ¼dy krok przetwarza dane i przekazuje je dalej.
    
    PIPELINE W TYM SKRYPCIE:
    1. Parsowanie argumentÃ³w (gdzie sÄ… dane?)
    2. Åadowanie surowych danych WTS
    3. Przetwarzanie do formatu LLaVA
    4. Zapisywanie wynikÃ³w do plikÃ³w JSON
    
    DLACZEGO ROZDZIELAMY TRAIN I VAL:
    - train (treningowy) - dane do uczenia modelu
    - val (walidacyjny) - dane do sprawdzenia czy model dobrze siÄ™ uczy
    
    To jak podziaÅ‚ na:
    - Zadania domowe (uczymy siÄ™)
    - Sprawdziany (sprawdzamy wiedzÄ™)
    
    Model NIE widzi danych val podczas treningu - inaczej byÅ‚oby to Å›ciÄ…ganie!

    ğŸ“ PROCES KROK PO KROKU:
    """
    # ğŸ“ KROK 1: Parsuj argumenty i przygotuj katalogi
    user_path = parse_arguments()
    os.makedirs(user_path, exist_ok=True)  # UtwÃ³rz katalog jeÅ›li nie istnieje

    print("Starting WTS annotations processing...")

    # ğŸ“ KROK 2: PrzetwÃ³rz zbiory treningowe MCQ
    print("\nğŸ“š Przetwarzanie zbioru treningowego...")
    
    # ğŸ“ PrzetwÃ³rz gÅ‚Ã³wny zbiÃ³r treningowy
    train_mcq_env_dataset = process_wts_environment_mcq(
        os.path.join(user_path, "annotations", "vqa", "train"), 
        "train"
    )
    
    # ğŸ“ Dodaj rÃ³wnieÅ¼ dane "normal_trimmed" (przyciÄ™te wideo)
    # += oznacza "dodaj do istniejÄ…cej listy"
    train_mcq_env_dataset += process_wts_environment_mcq(
        os.path.join(user_path, "annotations", "vqa", "train", "normal_trimmed"),
        "train",
    )

    # ğŸ“ KROK 3: Zapisz zbiÃ³r treningowy do JSON
    output_dir = user_path
    os.makedirs(output_dir, exist_ok=True)
    
    output_file = os.path.join(output_dir, "environment_mcq_llava_train.json")
    with open(output_file, "w") as f:
        # indent=4 sprawia Å¼e JSON jest czytelny (sformatowany)
        json.dump(train_mcq_env_dataset, f, indent=4)
    
    print(f"âœ… Zapisano zbiÃ³r treningowy: {output_file}")

    # ğŸ“ KROK 4: PrzetwÃ³rz zbiory walidacyjne MCQ
    print("\nğŸ” Przetwarzanie zbioru walidacyjnego...")
    
    val_mcq_env_dataset = process_wts_environment_mcq(
        os.path.join(user_path, "annotations", "vqa", "val"), 
        "val"
    )
    val_mcq_env_dataset += process_wts_environment_mcq(
        os.path.join(user_path, "annotations", "vqa", "val", "normal_trimmed"), 
        "val"
    )

    # ğŸ“ KROK 5: Zapisz zbiÃ³r walidacyjny
    output_file = os.path.join(output_dir, "environment_mcq_llava_val.json")
    with open(output_file, "w") as f:
        json.dump(val_mcq_env_dataset, f, indent=4)
    
    print(f"âœ… Zapisano zbiÃ³r walidacyjny: {output_file}")

    # ğŸ“ KROK 6: Podsumowanie
    print("\n" + "="*60)
    print("âœ¨ Przetwarzanie adnotacji WTS zakoÅ„czone!")
    print("="*60)
    print(f"ğŸ“Š Statystyki:")
    print(f"   â€¢ ZbiÃ³r treningowy:    {len(train_mcq_env_dataset):,} prÃ³bek")
    print(f"   â€¢ ZbiÃ³r walidacyjny:   {len(val_mcq_env_dataset):,} prÃ³bek")
    print(f"   â€¢ Suma:                {len(train_mcq_env_dataset) + len(val_mcq_env_dataset):,} prÃ³bek")
    print("\nğŸ¯ Dane gotowe do treningu modelu!")
    print("="*60)


if __name__ == "__main__":
    main()
