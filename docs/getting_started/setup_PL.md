# RozpoczÄ™cie pracy (Getting Started)

**ğŸ“ Dla studentÃ³w:** Ten przewodnik pomoÅ¼e Ci przygotowaÄ‡ komputer do pracy z modelami Cosmos. MoÅ¼e wydawaÄ‡ siÄ™ skomplikowany, ale przejdziemy przez to krok po kroku!

Ten przewodnik obejmuje niezbÄ™dne narzÄ™dzia i zaleÅ¼noÅ›ci potrzebne do skonfigurowania Å›rodowiska deweloperskiego do pracy z modelami Cosmos. Te narzÄ™dzia stanowiÄ… fundament dla kuratorowania danych, post-treningu modeli, ewaluacji i przepÅ‚ywÃ³w pracy wdroÅ¼eniowych we wszystkich projektach Cosmos.

---

## Konfiguracja repozytorium (Repository Setup)

**ğŸ“ Co to jest repozytorium?**  
Repozytorium to miejsce gdzie przechowywany jest caÅ‚y kod projektu. To jak folder, ale z historiÄ… wszystkich zmian.

Sklonuj repozytorium Cosmos Cookbook i zainstaluj je w trybie deweloperskim:

```shell
# Sklonuj repozytorium (pobierz kod)
git clone git@github.com:nvidia-cosmos/cosmos-cookbook.git

# WejdÅº do katalogu
cd cosmos-cookbook
```

**ğŸ“ Co robi kaÅ¼da komenda:**
- `git clone` - pobiera caÅ‚e repozytorium na TwÃ³j komputer
- `cd cosmos-cookbook` - zmienia aktualny katalog (change directory)

### Struktura Cookbook

**ğŸ“ Zrozumienie organizacji projektu:**

Cosmos Cookbook jest zorganizowany w dwa gÅ‚Ã³wne katalogi:

#### ğŸ“ `docs/` - Dokumentacja

Zawiera ÅºrÃ³dÅ‚owÄ… dokumentacjÄ™ w plikach markdown:

- **Przewodniki techniczne** - jak uÅ¼ywaÄ‡ poszczegÃ³lnych funkcji
- **PrzepÅ‚ywy pracy (workflows)** - kompletne procesy od A do Z
- **PrzykÅ‚ady** - gotowe do uruchomienia case studies
- **Tutoriale** - nauka krok po kroku

**ğŸ“ Markdown (.md):** Prosty format tekstu z formatowaniem. UÅ¼ywany do dokumentacji.

#### ğŸ“ `scripts/` - Kod wykonywany

Zawiera wszystkie wykonywalne skrypty, do ktÃ³rych odwoÅ‚uje siÄ™ dokumentacja:

- **Przetwarzanie danych** - przygotowanie zbiorÃ³w danych do treningu
- **Pipeline'y ewaluacji** - ocena jakoÅ›ci modeli
- **Konfiguracje post-trainingu** - ustawienia dostrajania modeli
- **NarzÄ™dzia automatyzacji** - skrypty pomocnicze

**ğŸ“ Dlaczego taki podziaÅ‚?**

```
Typowy przepÅ‚yw pracy:
1. Czytasz docs/recipes/inference/tutorial.md
2. Widzisz tam: "uruchom scripts/examples/inference.py"
3. Uruchamiasz skrypt
4. Wracasz do dokumentacji po wiÄ™cej informacji
```

Ta struktura oddziela dokumentacjÄ™ od praktycznej implementacji, uÅ‚atwiajÄ…c nawigacjÄ™ miÄ™dzy czytaniem o przepÅ‚ywach pracy a wykonywaniem odpowiednich skryptÃ³w.

> **Uwaga:** Te kroki instalacji bÄ™dÄ… aktualizowane w miarÄ™ przygotowywania zewnÄ™trznego repozytorium do publicznego wydania.

---

## Wymagania wstÄ™pne (Prerequisites)

**ğŸ“ WyjaÅ›nienie:** Przed rozpoczÄ™ciem musisz sprawdziÄ‡ czy TwÃ³j komputer speÅ‚nia wymagania. Cosmos wymaga duÅ¼ej mocy obliczeniowej!

Przed rozpoczÄ™ciem upewnij siÄ™, Å¼e speÅ‚niasz nastÄ™pujÄ…ce wymagania.

### SprzÄ™t (Hardware)

**ğŸ“ WAÅ»NE - Wymagania GPU:**

Do uruchamiania przepisÃ³w cookbook i przepÅ‚ywÃ³w pracy potrzebujesz:

- **Inferencja (uÅ¼ywanie modeli):** minimum 1 GPU
- **Trening (uczenie modeli):** minimum 4 GPU (zalecane 8 GPU)
- **Architektura:** Ampere lub nowsza (A100, H100)

**ğŸ“ Co to jest GPU?**  
GPU (Graphics Processing Unit) to specjalistyczny procesor pierwotnie zaprojektowany do grafiki, ale idealny do AI. Modele AI wykonujÄ… miliony obliczeÅ„ rÃ³wnolegle - GPU jest w tym tysiÄ…ce razy szybsze niÅ¼ zwykÅ‚y procesor (CPU).

**ğŸ“ Popularne GPU dla AI:**
- **NVIDIA A100** - profesjonalna karta do data center (bardzo droga, ~$10,000)
- **NVIDIA H100** - najnowsza generacja, jeszcze wydajniejsza
- **RTX 4090** - wysokiej klasy karta konsumencka (moÅ¼e dziaÅ‚aÄ‡ dla maÅ‚ych modeli)

**ğŸ“ Co jeÅ›li nie mam GPU?**  
Nie martw siÄ™! MoÅ¼esz:
1. UÅ¼ywaÄ‡ chmury (zobacz sekcjÄ™ "Cloud Deployments" poniÅ¼ej)
2. CzytaÄ‡ dokumentacjÄ™ i uczyÄ‡ siÄ™ teorii
3. UruchamiaÄ‡ maÅ‚e przykÅ‚ady na CPU (bÄ™dzie wolno, ale zadziaÅ‚a)

Dla szczegÃ³Å‚owych wymagaÅ„ GPU i pamiÄ™ci dla kaÅ¼dego modelu Cosmos (Predict1, Predict2, Transfer1, etc.), zobacz dokumentacjÄ™ [NVIDIA Cosmos Prerequisites](https://docs.nvidia.com/cosmos/latest/prerequisites.html).

> **Uwaga**: GPU nie jest wymagane do renderowania lokalnej dokumentacji.

### Oprogramowanie (Software)

**ğŸ“ Lista narzÄ™dzi ktÃ³re musisz zainstalowaÄ‡:**

- **System operacyjny**: Ubuntu 24.04, 22.04, lub 20.04
  - **ğŸ“ Dlaczego Ubuntu?** To dystrybucja Linuxa z najlepszym wsparciem dla AI/ML
  - **ğŸ“ Czy mogÄ™ uÅ¼yÄ‡ Windows?** Niestety wiÄ™kszoÅ›Ä‡ narzÄ™dzi AI dziaÅ‚a tylko na Linux
  - **ğŸ“ Opcja:** MoÅ¼esz uÅ¼yÄ‡ WSL2 (Windows Subsystem for Linux) na Windows

- **Python**: Wersja 3.10+
  - **ğŸ“ Co to jest Python?** JÄ™zyk programowania, gÅ‚Ã³wny jÄ™zyk dla AI/ML
  - **ğŸ“ SprawdÅº wersjÄ™:** `python3 --version`

- **NVIDIA Container Toolkit**: 1.16.2 lub nowszy
  - **ğŸ“ Co to robi?** Pozwala Dockerowi uÅ¼ywaÄ‡ GPU
  - **ğŸ“ Bez tego:** Docker nie zobaczy Twojej karty graficznej

- **CUDA**: 12.4 lub nowszy
  - **ğŸ“ Co to jest CUDA?** Platforma NVIDIA do programowania GPU
  - **ğŸ“ Wymagane do:** Uruchamiania obliczeÅ„ AI na GPU

- **Docker Engine**
  - **ğŸ“ Co to jest Docker?** System konteneryzacji - jak maszyna wirtualna, ale lÅ¼ejsza
  - **ğŸ“ Dlaczego?** Zapewnia spÃ³jne Å›rodowisko (wszystko dziaÅ‚a tak samo)

- **SieÄ‡**: PoÅ‚Ä…czenie internetowe do pobierania modeli i zaleÅ¼noÅ›ci
  - **ğŸ“ Rozmiary plikÃ³w:** Modele AI mogÄ… mieÄ‡ 10-50 GB!

**ğŸ“ Sprawdzanie instalacji:**

```bash
# SprawdÅº system operacyjny
lsb_release -a

# SprawdÅº Python
python3 --version

# SprawdÅº CUDA
nvcc --version

# SprawdÅº Docker
docker --version

# SprawdÅº GPU
nvidia-smi
```

---

## Instalacja narzÄ™dzi ogÃ³lnych (Generic Tool Installation)

**ğŸ“ WyjaÅ›nienie:** Te narzÄ™dzia sÄ… potrzebne do zarzÄ…dzania innymi narzÄ™dziami. To jak "narzÄ™dzia do zarzÄ…dzania narzÄ™dziami"!

NastÄ™pujÄ…ce zaleÅ¼noÅ›ci systemowe sÄ… wymagane do uruchomienia Cosmos Cookbook:

### pkgx

**ğŸ“ Co to jest pkgx?**  
pkgx to nowoczesny menedÅ¼er pakietÃ³w, ktÃ³ry upraszcza instalacjÄ™ i zarzÄ…dzanie narzÄ™dziami CLI. Zapewnia izolowane Å›rodowiska i automatyczne rozwiÄ…zywanie zaleÅ¼noÅ›ci.

**ğŸ“ Dlaczego nie apt/yum?**  
- pkgx jest szybszy i prostszy
- Automatycznie zarzÄ…dza wersjami
- Nie wymaga uprawnieÅ„ sudo dla wiÄ™kszoÅ›ci rzeczy

[pkgx](https://docs.pkgx.sh/) - dokumentacja

```shell
# Instalacja przez brew (jeÅ›li masz) LUB przez skrypt instalacyjny
brew install pkgx || curl https://pkgx.sh | sh
```

**ğŸ“ Co robi ta komenda:**
- `brew install pkgx` - prÃ³buje zainstalowaÄ‡ przez Homebrew
- `||` - "lub" - jeÅ›li pierwsze siÄ™ nie uda, sprÃ³buj drugiego
- `curl https://pkgx.sh | sh` - pobierz i uruchom skrypt instalacyjny

### uv

**ğŸ“ Co to jest uv?**  
uv to szybki instalator i resolver pakietÃ³w Python, zaprojektowany jako zamiennik dla pip. Jest niezbÄ™dny do zarzÄ…dzania zaleÅ¼noÅ›ciami Python w projektach Cosmos.

**ğŸ“ pip vs uv:**
- **pip** - tradycyjny menedÅ¼er pakietÃ³w Python (wolniejszy)
- **uv** - nowoczesna alternatywa (10-100x szybsza!)

[uv](https://docs.astral.sh/uv/) - dokumentacja

```shell
pkgm install uv
```

**ğŸ“ Co robi ta komenda:**
Instaluje uv uÅ¼ywajÄ…c pkgm (czÄ™Å›Ä‡ pkgx)

### Hugging Face CLI

**ğŸ“ Co to jest Hugging Face?**  
Hugging Face to "GitHub dla modeli AI". To platforma gdzie znajdujÄ… siÄ™ tysiÄ…ce gotowych modeli AI, ktÃ³re moÅ¼esz pobraÄ‡ i uÅ¼yÄ‡.

**ğŸ“ Dlaczego potrzebujemy CLI?**  
CLI (Command Line Interface) pozwala pobraÄ‡ modele bezpoÅ›rednio z terminala, bez rÄ™cznego pobierania przez przeglÄ…darkÄ™.

[Hugging Face CLI](https://huggingface.co/docs/huggingface_hub/en/guides/cli) jest niezbÄ™dne do pobierania wytrenowanych checkpointÃ³w modeli i zbiorÃ³w danych z Hugging Face Hub.

```shell
# Instalacja
pkgm install huggingface-cli

# Logowanie (potrzebne do pobierania modeli)
huggingface-cli login
```

**ğŸ“ Proces logowania:**
1. Uruchom `huggingface-cli login`
2. Poprosi CiÄ™ o token
3. IdÅº na https://huggingface.co/settings/tokens
4. UtwÃ³rz nowy token (read access wystarczy)
5. Skopiuj i wklej token

> **Uwaga**: Potrzebujesz konta Hugging Face i tokenu dostÄ™pu do uwierzytelniania.

**ğŸ“ Dlaczego token jest bezpieczny?**  
Token dziaÅ‚a jak hasÅ‚o, ale moÅ¼esz je odwoÅ‚aÄ‡ w dowolnym momencie. Nigdy nie podawaj swojego gÅ‚Ã³wnego hasÅ‚a do skryptÃ³w.

---

## Szybki start wdroÅ¼eÅ„ w chmurze (Cloud Deployments Quick Start)

**ğŸ“ Co to jest wdroÅ¼enie w chmurze?**  
Zamiast uÅ¼ywaÄ‡ wÅ‚asnego komputera, wynajmujesz moc obliczeniowÄ… w internecie. To jak Netflix dla GPU - pÅ‚acisz za uÅ¼ycie, nie musisz kupowaÄ‡ sprzÄ™tu.

**ğŸ“ Kiedy uÅ¼ywaÄ‡ chmury:**
- âœ… Nie masz odpowiedniego GPU
- âœ… Chcesz szybko przetestowaÄ‡
- âœ… Potrzebujesz duÅ¼o mocy na krÃ³tki czas
- âœ… Nie chcesz konfigurowaÄ‡ Å›rodowiska

**ğŸ“ Wady chmury:**
- âŒ Kosztuje (ale czÄ™sto mniej niÅ¼ zakup GPU)
- âŒ Potrzebujesz dobrego internetu
- âŒ Dane sÄ… "w chmurze" (kwestia prywatnoÅ›ci)

Te przewodniki wdroÅ¼eÅ„ w chmurze pomogÄ… Ci wdroÅ¼yÄ‡ i uruchomiÄ‡ modele Cosmos bez lokalnej konfiguracji infrastruktury.

### DostÄ™pne opcje chmurowe:

#### Brev - Platforma GPU w chmurze

**ğŸ“ Co to jest Brev?**  
Brev to platforma oferujÄ…ca Å‚atwy dostÄ™p do GPU w chmurze. Kliknij kilka przyciskÃ³w i masz dziaÅ‚ajÄ…cy serwer z GPU!

- **[Rozpocznij z Cosmos Reason1 na Brev](brev/reason1/reason1_on_brev.md)** 
  - WdroÅ¼enie Cosmos Reason1 do rozumowania Physical AI
  - Ten przewodnik obejmuje provisioning, konfiguracjÄ™ i pierwszÄ… inferencjÄ™
  - **ğŸ“ Dla kogo:** Åšwietne do eksperymentowania z analizÄ… wideo

- **[Rozpocznij z Transfer2.5 i Predict2.5 na Brev](brev/transfer2_5/transfer_and_predict_on_brev.md)** 
  - Konfiguracja Transfer2.5 (generowanie wideo) i Predict2.5 (predykcja Å›wiata)
  - Infrastruktura Brev cloud z przykÅ‚adowymi przepÅ‚ywami pracy
  - **ğŸ“ Dla kogo:** JeÅ›li chcesz generowaÄ‡ lub przeksztaÅ‚caÄ‡ wideo

**ğŸ“ Typowe koszty (orientacyjnie):**
- GPU klasy A100: ~$2-4 za godzinÄ™
- Tip: Zatrzymuj instancjÄ™ gdy nie uÅ¼ywasz!
- Wiele platform oferuje darmowe kredyty na start

---

## ğŸ“ Podsumowanie dla studentÃ³w

### Sprawdzenie gotowoÅ›ci:

**Poziom 1: Czytanie dokumentacji (kaÅ¼dy)**
- âœ… Komputer z przeglÄ…darkÄ…
- âœ… PoÅ‚Ä…czenie internetowe
- âœ… CiekawoÅ›Ä‡ i chÄ™Ä‡ nauki!

**Poziom 2: Uruchamianie maÅ‚ych przykÅ‚adÃ³w (studenci)**
- âœ… Linux (Ubuntu zalecane)
- âœ… Python 3.10+
- âœ… Podstawowa znajomoÅ›Ä‡ terminala

**Poziom 3: PeÅ‚ne przepÅ‚ywy pracy (zaawansowani)**
- âœ… GPU (wÅ‚asne lub w chmurze)
- âœ… CUDA i Docker
- âœ… ZnajomoÅ›Ä‡ Git i Python

### ÅšcieÅ¼ka nauki:

```mermaid
1. Czytaj dokumentacjÄ™
   â†“
2. Eksperymentuj z maÅ‚ymi przykÅ‚adami (CPU)
   â†“
3. SprÃ³buj chmury (darmowy kredyt)
   â†“
4. RozwaÅ¼ wÅ‚asne GPU (gdy wiesz Å¼e bÄ™dziesz uÅ¼ywaÄ‡)
```

### NastÄ™pne kroki:

1. **[README.md](../../README.md)** - PrzeglÄ…d caÅ‚ego projektu
2. **[CONTRIBUTING_PL.md](../../CONTRIBUTING_PL.md)** - Jak wspÃ³Å‚tworzyÄ‡
3. **Recipes (Przepisy)** - WyprÃ³buj pierwszy przepis!

### Potrzebujesz pomocy?

- **GitHub Issues:** Zadaj pytanie w Issues
- **Dokumentacja:** Zawsze czytaj najpierw dokumentacjÄ™
- **Community:** SpoÅ‚ecznoÅ›Ä‡ jest przyjazna!

**PamiÄ™taj:** KaÅ¼dy ekspert kiedyÅ› byÅ‚ poczÄ…tkujÄ…cym. Zadawaj pytania, eksperymentuj i ucz siÄ™! ğŸš€

---

## Dodatkowe zasoby

### Kursy online (darmowe):
- **fast.ai** - Praktyczny deep learning
- **Hugging Face Course** - Uczenie siÄ™ NLP i transformerÃ³w
- **CUDA Programming** - Programowanie GPU

### KsiÄ…Å¼ki:
- "Deep Learning" by Ian Goodfellow
- "Hands-On Machine Learning" by AurÃ©lien GÃ©ron

### YouTube:
- 3Blue1Brown - Wizualizacje AI
- Two Minute Papers - Najnowsze badania AI
- Yannic Kilcher - SzczegÃ³Å‚owe omÃ³wienia papers

**Powodzenia w nauce! ğŸ“âœ¨**
